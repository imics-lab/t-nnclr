{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "from pretrain import pretrain\n",
    "from finetune import finetune, FineTuningConfig\n",
    "from config import *\n",
    "from data_loader import load_and_preprocess_har_data\n",
    "import os\n",
    "import gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data/X_unlabeled.npy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1vK1flNSOMADCmYnxQjSHoq3FupZ42Anq\n",
      "From (redirected): https://drive.google.com/uc?id=1vK1flNSOMADCmYnxQjSHoq3FupZ42Anq&confirm=t&uuid=817e0396-b7c7-470b-93d9-fbaf3899cc56\n",
      "To: /mnt/batch/tasks/shared/LS_root/mounts/clusters/habibirani-gpu/code/Users/habibirani/t-nnclr/data/X_unlabeled.npy\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 892M/892M [00:20<00:00, 43.9MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded data/X_unlabeled.npy.\n",
      "\n",
      "Downloading data/X.npy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1sXJX-1Tge5voIPXxFhMene1HLKhfp9gm\n",
      "To: /mnt/batch/tasks/shared/LS_root/mounts/clusters/habibirani-gpu/code/Users/habibirani/t-nnclr/data/X.npy\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 17.0M/17.0M [00:00<00:00, 57.2MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded data/X.npy.\n",
      "\n",
      "Downloading data/y.npy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1jgNQ2M5mrtjqo7V_fCpHbGigslc1jjOC\n",
      "To: /mnt/batch/tasks/shared/LS_root/mounts/clusters/habibirani-gpu/code/Users/habibirani/t-nnclr/data/y.npy\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127k/127k [00:00<00:00, 2.20MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded data/y.npy.\n",
      "\n",
      "Downloading data/sub.npy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1ZXSvlVzxipCP_EDsUMtPE4TM0ygVMxaJ\n",
      "To: /mnt/batch/tasks/shared/LS_root/mounts/clusters/habibirani-gpu/code/Users/habibirani/t-nnclr/data/sub.npy\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25.5k/25.5k [00:00<00:00, 14.1MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded data/sub.npy.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def download_file_from_google_drive(file_id, destination):\n",
    "    url = f'https://drive.google.com/uc?id={file_id}'\n",
    "    gdown.download(url, destination, quiet=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create data directory if it doesn't exist\n",
    "    if not os.path.exists('data'):\n",
    "        os.makedirs('data')\n",
    "\n",
    "    # Define file IDs and destination paths\n",
    "    files_to_download = [\n",
    "        {\n",
    "            'file_id': '1vK1flNSOMADCmYnxQjSHoq3FupZ42Anq',\n",
    "            'dest_path': 'data/X_unlabeled.npy'\n",
    "        },\n",
    "        {\n",
    "            'file_id': '1sXJX-1Tge5voIPXxFhMene1HLKhfp9gm',\n",
    "            'dest_path': 'data/X.npy'\n",
    "        },\n",
    "        {\n",
    "            'file_id': '1jgNQ2M5mrtjqo7V_fCpHbGigslc1jjOC',\n",
    "            'dest_path': 'data/y.npy'\n",
    "        },\n",
    "        {\n",
    "            'file_id': '1ZXSvlVzxipCP_EDsUMtPE4TM0ygVMxaJ',\n",
    "            'dest_path': 'data/sub.npy'\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    # Download each file\n",
    "    for file_info in files_to_download:\n",
    "        print(f\"Downloading {file_info['dest_path']}...\")\n",
    "        download_file_from_google_drive(file_info['file_id'], file_info['dest_path'])\n",
    "        print(f\"Downloaded {file_info['dest_path']}.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loaded data shapes:\n",
      "INFO:__main__:X_unlabeled: (331964, 96, 4)\n",
      "INFO:__main__:X_labeled: (3168, 96, 4)\n",
      "INFO:__main__:y: (3168,)\n",
      "INFO:__main__:subjects: (3168,)\n",
      "INFO:__main__:Number of unique subjects: 3\n",
      "INFO:__main__:Number of unique classes: 6\n",
      "INFO:__main__:Labels encoded successfully\n",
      "INFO:__main__:Data standardization completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data loading test completed successfully!\n",
      "Unlabeled data shape: (331964, 96, 4)\n",
      "Labeled data shape: (3168, 96, 4)\n",
      "Labels shape: (3168,)\n",
      "Subjects shape: (3168,)\n"
     ]
    }
   ],
   "source": [
    "def load_and_preprocess_har_data(data_dir='./data', logger=None):\n",
    "    \"\"\"\n",
    "    Load and preprocess HAR dataset.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Directory containing the data files\n",
    "        logger: Optional logger instance\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (X_unlabeled, X_labeled, y, subjects)\n",
    "            - X_unlabeled: Unlabeled data array\n",
    "            - X_labeled: Labeled data array\n",
    "            - y: Labels array\n",
    "            - subjects: Subject IDs array\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data_dir = Path(data_dir)\n",
    "        \n",
    "        # Load data\n",
    "        X_unlabeled = np.load(data_dir / 'X_unlabeled.npy')\n",
    "        # X_unlabeled = np.load(data_dir / 'X.npy')\n",
    "        X_labeled = np.load(data_dir / 'X.npy')\n",
    "        y = np.load(data_dir / 'y.npy').squeeze()\n",
    "        subjects = np.load(data_dir / 'sub.npy').squeeze()\n",
    "        \n",
    "        # Use only first 4 channels of the data\n",
    "        X_unlabeled = X_unlabeled[:, :, :4]\n",
    "        X_labeled = X_labeled[:, :, :4]\n",
    "        \n",
    "        if logger:\n",
    "            logger.info(f\"Loaded data shapes:\")\n",
    "            logger.info(f\"X_unlabeled: {X_unlabeled.shape}\")\n",
    "            logger.info(f\"X_labeled: {X_labeled.shape}\")\n",
    "            logger.info(f\"y: {y.shape}\")\n",
    "            logger.info(f\"subjects: {subjects.shape}\")\n",
    "            logger.info(f\"Number of unique subjects: {len(np.unique(subjects))}\")\n",
    "            logger.info(f\"Number of unique classes: {len(np.unique(y))}\")\n",
    "        \n",
    "        # Convert labels to integers\n",
    "        le = LabelEncoder()\n",
    "        y = le.fit_transform(y)\n",
    "        if logger:\n",
    "            logger.info(\"Labels encoded successfully\")\n",
    "        \n",
    "        # Standardize the data\n",
    "        scaler = StandardScaler()\n",
    "        \n",
    "        # Reshape for standardization\n",
    "        orig_shape_unlabeled = X_unlabeled.shape\n",
    "        orig_shape_labeled = X_labeled.shape\n",
    "        \n",
    "        # Combine all data for computing statistics\n",
    "        combined = np.vstack([\n",
    "            X_unlabeled.reshape(-1, X_unlabeled.shape[-1]),\n",
    "            X_labeled.reshape(-1, X_labeled.shape[-1])\n",
    "        ])\n",
    "        \n",
    "        # Fit on combined data\n",
    "        scaler.fit(combined)\n",
    "        \n",
    "        # Transform separately and reshape back\n",
    "        X_unlabeled = scaler.transform(\n",
    "            X_unlabeled.reshape(-1, X_unlabeled.shape[-1])\n",
    "        ).reshape(orig_shape_unlabeled)\n",
    "        \n",
    "        X_labeled = scaler.transform(\n",
    "            X_labeled.reshape(-1, X_labeled.shape[-1])\n",
    "        ).reshape(orig_shape_labeled)\n",
    "        \n",
    "        if logger:\n",
    "            logger.info(\"Data standardization completed\")\n",
    "        \n",
    "        return X_unlabeled, X_labeled, y, subjects\n",
    "        \n",
    "    except Exception as e:\n",
    "        if logger:\n",
    "            logger.error(f\"Error loading data: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Test data loading\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    logger = logging.getLogger(__name__)\n",
    "    \n",
    "    data_dir = Path.cwd() / 'data'\n",
    "    X_unlabeled, X_labeled, y, subjects = load_and_preprocess_har_data(data_dir, logger)\n",
    "    \n",
    "    print(\"\\nData loading test completed successfully!\")\n",
    "    print(f\"Unlabeled data shape: {X_unlabeled.shape}\")\n",
    "    print(f\"Labeled data shape: {X_labeled.shape}\")\n",
    "    print(f\"Labels shape: {y.shape}\")\n",
    "    print(f\"Subjects shape: {subjects.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logging(experiment_dir):\n",
    "    \"\"\"Setup logging configuration.\"\"\"\n",
    "    experiment_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    log_file = experiment_dir / 'experiment.log'\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_file),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "    return logging.getLogger(__name__)\n",
    "\n",
    "def run_cross_validation_experiment(\n",
    "    data_dir='./data',\n",
    "    experiment_dir=None,\n",
    "    pretrain_epochs=PRETRAIN_EPOCHS,\n",
    "    finetune_epochs=FINETUNE_EPOCHS,\n",
    "    freeze_encoder=False,\n",
    "    encoder_lr=LEARNING_RATE,\n",
    "    head_lr=LEARNING_RATE\n",
    "):\n",
    "    \"\"\"\n",
    "    Run NNCLR experiment with Leave-One-Subject-Out cross validation.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Directory containing the data files\n",
    "        experiment_dir: Directory to save experiment results\n",
    "        pretrain_epochs: Number of pretraining epochs\n",
    "        finetune_epochs: Number of finetuning epochs\n",
    "        freeze_encoder: Whether to freeze encoder during fine-tuning\n",
    "        encoder_lr: Learning rate for encoder during fine-tuning\n",
    "        head_lr: Learning rate for classification head during fine-tuning\n",
    "    \n",
    "    Returns:\n",
    "        dict: Results dictionary containing accuracies and confusion matrices\n",
    "    \"\"\"\n",
    "    # Setup experiment directory and logging\n",
    "    if experiment_dir is None:\n",
    "        experiment_dir = Path.cwd() / 'experiments' / datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    else:\n",
    "        experiment_dir = Path(experiment_dir)\n",
    "    \n",
    "    logger = setup_logging(experiment_dir)\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    logger.info(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load data\n",
    "    X_unlabeled, X_labeled, y, subjects = load_and_preprocess_har_data(data_dir, logger)\n",
    "    \n",
    "    # Create fine-tuning configuration\n",
    "    finetune_config = FineTuningConfig(\n",
    "        freeze_encoder=freeze_encoder,\n",
    "        encoder_lr=encoder_lr,\n",
    "        head_lr=head_lr,\n",
    "        num_epochs=finetune_epochs\n",
    "    )\n",
    "    \n",
    "    # Perform pretraining once using only unlabeled data\n",
    "    logger.info(\"Starting pretraining phase...\")\n",
    "    pretrain_save_path = experiment_dir / 'pretrained_model.pt'\n",
    "    \n",
    "    pretrained_model, pretrain_history = pretrain(\n",
    "        X_unlabeled=X_unlabeled,\n",
    "        num_epochs=pretrain_epochs,\n",
    "        device=device,\n",
    "        save_path=pretrain_save_path\n",
    "    )\n",
    "    \n",
    "    # Save pretraining history\n",
    "    np.save(experiment_dir / 'pretrain_history.npy', pretrain_history)\n",
    "    \n",
    "    # Setup cross-validation\n",
    "    cv = LeaveOneGroupOut()\n",
    "    splits = list(cv.split(X_labeled, y, subjects))\n",
    "    logger.info(f\"Running Leave-One-Subject-Out CV with {len(splits)} folds\")\n",
    "    \n",
    "    # Rest of the code remains unchanged\n",
    "    results = {\n",
    "        'fold_accuracies': [],\n",
    "        'confusion_matrices': [],\n",
    "        'finetune_histories': []\n",
    "    }\n",
    "    \n",
    "    # Run cross-validation\n",
    "    for fold, (train_idx, test_idx) in enumerate(splits):\n",
    "        fold_dir = experiment_dir / f'fold_{fold}'\n",
    "        fold_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        logger.info(f\"\\nStarting Fold {fold + 1}/{len(splits)}\")\n",
    "        \n",
    "        # Split data for this fold\n",
    "        X_train = X_labeled[train_idx]\n",
    "        y_train = y[train_idx]\n",
    "        X_test = X_labeled[test_idx]\n",
    "        y_test = y[test_idx]\n",
    "        \n",
    "        # Finetuning phase\n",
    "        logger.info(\"Starting finetuning phase...\")\n",
    "        finetune_save_path = fold_dir / 'finetuned_model.pt'\n",
    "        \n",
    "        # Fine-tune using pretrained weights\n",
    "        model, finetune_history = finetune(\n",
    "            pretrained_model_path=pretrain_save_path,\n",
    "            X_train=X_train,\n",
    "            y_train=y_train,\n",
    "            X_test=X_test,\n",
    "            y_test=y_test,\n",
    "            config=finetune_config,\n",
    "            device=device,\n",
    "            save_path=finetune_save_path\n",
    "        )\n",
    "        \n",
    "        # Store results for this fold\n",
    "        results['fold_accuracies'].append(finetune_history['best_acc'])\n",
    "        results['confusion_matrices'].append(finetune_history['confusion_matrix'])\n",
    "        results['finetune_histories'].append(finetune_history)\n",
    "        \n",
    "        logger.info(f\"Fold {fold + 1} - Best Test Accuracy: {finetune_history['best_acc']:.2f}%\")\n",
    "    \n",
    "    # Calculate and log final results\n",
    "    accuracies = np.array(results['fold_accuracies'])\n",
    "    cumulative_confusion = sum(results['confusion_matrices'])\n",
    "    \n",
    "    logger.info(\"\\nFinal Results:\")\n",
    "    logger.info(f\"Mean Accuracy: {accuracies.mean():.2f}% +/- {accuracies.std():.2f}%\")\n",
    "    logger.info(\"\\nCumulative Confusion Matrix:\")\n",
    "    logger.info(\"\\n\" + str(cumulative_confusion))\n",
    "    \n",
    "    # Save final results\n",
    "    np.save(experiment_dir / 'accuracies.npy', accuracies)\n",
    "    np.save(experiment_dir / 'confusion_matrices.npy', results['confusion_matrices'])\n",
    "    np.save(experiment_dir / 'cumulative_confusion.npy', cumulative_confusion)\n",
    "    \n",
    "    # Save summary statistics\n",
    "    with open(experiment_dir / 'summary.txt', 'w') as f:\n",
    "        f.write(\"Experiment Configuration:\\n\")\n",
    "        f.write(f\"Freeze encoder: {freeze_encoder}\\n\")\n",
    "        f.write(f\"Encoder learning rate: {encoder_lr}\\n\")\n",
    "        f.write(f\"Head learning rate: {head_lr}\\n\")\n",
    "        f.write(f\"Pretrain epochs: {pretrain_epochs}\\n\")\n",
    "        f.write(f\"Finetune epochs: {finetune_epochs}\\n\\n\")\n",
    "        f.write(f\"Mean Accuracy: {accuracies.mean():.2f}% +/- {accuracies.std():.2f}%\\n\")\n",
    "        f.write(f\"Individual Fold Accuracies: {accuracies.tolist()}\\n\")\n",
    "        f.write(f\"\\nCumulative Confusion Matrix:\\n{cumulative_confusion}\")\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loaded data shapes:\n",
      "INFO:__main__:X_unlabeled: (331964, 96, 4)\n",
      "INFO:__main__:X_labeled: (3168, 96, 4)\n",
      "INFO:__main__:y: (3168,)\n",
      "INFO:__main__:subjects: (3168,)\n",
      "INFO:__main__:Number of unique subjects: 3\n",
      "INFO:__main__:Number of unique classes: 6\n",
      "INFO:__main__:Labels encoded successfully\n",
      "INFO:__main__:Data standardization completed\n",
      "INFO:__main__:Starting pretraining phase...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining on device: cuda\n",
      "Unlabeled data shape: (331964, 96, 4)\n",
      "\n",
      "Starting pretraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5186/5186 [01:56<00:00, 44.45it/s, loss=0.5881]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/2\n",
      "Loss: 0.5881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/2: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5186/5186 [01:55<00:00, 44.94it/s, loss=0.3655]\n",
      "INFO:__main__:Running Leave-One-Subject-Out CV with 3 folds\n",
      "INFO:__main__:\n",
      "Starting Fold 1/3\n",
      "INFO:__main__:Starting finetuning phase...\n",
      "/mnt/batch/tasks/shared/LS_root/mounts/clusters/habibirani-gpu/code/Users/habibirani/t-nnclr/finetune.py:247: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(pretrained_model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/2\n",
      "Loss: 0.3654\n",
      "\n",
      "Model saved to /mnt/batch/tasks/shared/LS_root/mounts/clusters/habibirani-gpu/code/Users/habibirani/t-nnclr/experiments/20250312_165207/pretrained_model.pt\n",
      "Finetuning on device: cuda\n",
      "Training data shape: (2121, 96, 4)\n",
      "Test data shape: (1047, 96, 4)\n",
      "Encoder frozen: False\n",
      "Encoder LR: 0.001\n",
      "Head LR: 0.001\n",
      "\n",
      "Starting finetuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 88.86it/s, loss=1.1832, acc=66.05%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/2\n",
      "Train Loss: 1.0092 | Train Acc: 66.05%\n",
      "Test Loss: 0.8436 | Test Acc: 56.92%\n",
      "Best Test Acc: 56.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/2: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 89.97it/s, loss=0.5472, acc=81.19%]\n",
      "INFO:__main__:Fold 1 - Best Test Accuracy: 74.88%\n",
      "INFO:__main__:\n",
      "Starting Fold 2/3\n",
      "INFO:__main__:Starting finetuning phase...\n",
      "/mnt/batch/tasks/shared/LS_root/mounts/clusters/habibirani-gpu/code/Users/habibirani/t-nnclr/finetune.py:247: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(pretrained_model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/2\n",
      "Train Loss: 0.4989 | Train Acc: 81.19%\n",
      "Test Loss: 0.9980 | Test Acc: 74.88%\n",
      "Best Test Acc: 74.88%\n",
      "Finetuning on device: cuda\n",
      "Training data shape: (2138, 96, 4)\n",
      "Test data shape: (1030, 96, 4)\n",
      "Encoder frozen: False\n",
      "Encoder LR: 0.001\n",
      "Head LR: 0.001\n",
      "\n",
      "Starting finetuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 88.50it/s, loss=1.2389, acc=61.79%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/2\n",
      "Train Loss: 1.0203 | Train Acc: 61.79%\n",
      "Test Loss: 0.9193 | Test Acc: 57.09%\n",
      "Best Test Acc: 57.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/2: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 89.78it/s, loss=0.6748, acc=77.55%]\n",
      "INFO:__main__:Fold 2 - Best Test Accuracy: 57.09%\n",
      "INFO:__main__:\n",
      "Starting Fold 3/3\n",
      "INFO:__main__:Starting finetuning phase...\n",
      "/mnt/batch/tasks/shared/LS_root/mounts/clusters/habibirani-gpu/code/Users/habibirani/t-nnclr/finetune.py:247: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(pretrained_model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/2\n",
      "Train Loss: 0.5954 | Train Acc: 77.55%\n",
      "Test Loss: 0.8624 | Test Acc: 56.89%\n",
      "Best Test Acc: 57.09%\n",
      "Finetuning on device: cuda\n",
      "Training data shape: (2077, 96, 4)\n",
      "Test data shape: (1091, 96, 4)\n",
      "Encoder frozen: False\n",
      "Encoder LR: 0.001\n",
      "Head LR: 0.001\n",
      "\n",
      "Starting finetuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 87.97it/s, loss=1.2216, acc=61.39%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/2\n",
      "Train Loss: 1.0365 | Train Acc: 61.39%\n",
      "Test Loss: 0.8326 | Test Acc: 67.00%\n",
      "Best Test Acc: 67.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/2: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 88.88it/s, loss=0.7015, acc=74.92%]\n",
      "INFO:__main__:Fold 3 - Best Test Accuracy: 70.12%\n",
      "INFO:__main__:\n",
      "Final Results:\n",
      "INFO:__main__:Mean Accuracy: 67.36% +/- 7.52%\n",
      "INFO:__main__:\n",
      "Cumulative Confusion Matrix:\n",
      "INFO:__main__:\n",
      "[[236   1   0   3 160  90]\n",
      " [  0 480   0   0   6  34]\n",
      " [  0   0 328 196   0   0]\n",
      " [  0   0   8 520   0   0]\n",
      " [ 19   3   0   7 414 125]\n",
      " [ 48  36   0   1 294 159]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/2\n",
      "Train Loss: 0.5952 | Train Acc: 74.92%\n",
      "Test Loss: 0.7641 | Test Acc: 70.12%\n",
      "Best Test Acc: 70.12%\n",
      "\n",
      "Experiment completed!\n",
      "Results saved to /mnt/batch/tasks/shared/LS_root/mounts/clusters/habibirani-gpu/code/Users/habibirani/t-nnclr/experiments/20250312_165207\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Set paths\n",
    "    data_dir = Path.cwd() / 'data'\n",
    "    experiment_dir = Path.cwd() / 'experiments' / datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    \n",
    "    # Run experiment with specific configuration\n",
    "    results = run_cross_validation_experiment(\n",
    "        data_dir=data_dir,\n",
    "        experiment_dir=experiment_dir,\n",
    "        pretrain_epochs=PRETRAIN_EPOCHS,\n",
    "        finetune_epochs=FINETUNE_EPOCHS,\n",
    "        freeze_encoder=False,\n",
    "        encoder_lr=LEARNING_RATE,\n",
    "        head_lr=LEARNING_RATE\n",
    "    )\n",
    "    \n",
    "    print(\"\\nExperiment completed!\")\n",
    "    print(f\"Results saved to {experiment_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
